import feedparser
import time
import datetime
import os
import re 
from config import RSS_SOURCES
from utils import get_timestamp, load_history, save_history, send_discord_webhook
from aya_brain import aya_process_news

def extract_image(entry):
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á URL ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Ç‡πà‡∏≤‡∏ß"""
    # 1. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å media_content (Reddit/News ‡∏°‡∏±‡∏Å‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ)
    if 'media_content' in entry:
        try:
            return entry.media_content[0]['url']
        except: pass
    
    # 2. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å media_thumbnail
    if 'media_thumbnail' in entry:
        try:
            return entry.media_thumbnail[0]['url']
        except: pass

    # 3. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å links (‡∏û‡∏ß‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö enclosure)
    if 'links' in entry:
        for link in entry.links:
            if link.type.startswith('image/'):
                return link.href

    # 4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡πÅ‡∏Å‡∏∞‡∏à‡∏≤‡∏Å HTML content ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    content_html = ""
    if 'content' in entry:
        content_html = entry.content[0].value
    elif 'summary' in entry:
        content_html = entry.summary
        
    if content_html:
        # ‡πÉ‡∏ä‡πâ Regular Expression ‡∏´‡∏≤ tag <img src="...">
        match = re.search(r'<img [^>]*src="([^"]+)"', content_html)
        if match:
            return match.group(1)
            
    return None

def run_once():
    print(f"[{datetime.datetime.now()}] üå™Ô∏è ‡∏≠‡∏≤‡∏¢‡∏∞‡∏ï‡∏∑‡πà‡∏ô‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πà‡∏≤‡∏ß‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà...")
    
    webhook_env = os.getenv("DISCORD_WEBHOOK_URL")
    target_webhooks = []
    if webhook_env:
        target_webhooks = [url.strip() for url in webhook_env.split(',') if url.strip()]
    
    print(f"üì° ‡∏û‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(target_webhooks)} ‡πÅ‡∏´‡πà‡∏á")

    read_history = load_history()
    new_items_found = False

    for source in RSS_SOURCES:
        print(f"Flying to... {source['name']} ü¶Ö")
        try:
            feed = feedparser.parse(source['url'])
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ 10 ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            for entry in feed.entries[:10]:
                news_id = entry.id if 'id' in entry else entry.link
                
                if news_id not in read_history:
                    pub_date = get_timestamp(entry)
                    print(f"üì∏ ‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà ({pub_date}): {entry.title}")
                    
                    content = ""
                    if 'content' in entry:
                        content = entry.content[0].value
                    elif 'summary' in entry:
                        content = entry.summary
                    
                    # 1. ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà)
                    image_url = extract_image(entry)
                    if image_url:
                        print(f"üñºÔ∏è ‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö: {image_url}")

                    # 2. ‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πà‡∏≤‡∏ß
                    aya_article = aya_process_news(source['type'], entry.title, content, entry.link, pub_date)
                    
                    if "AI_ERROR" in aya_article:
                        print(f"üí® Error: {aya_article}")
                    elif "SKIP" in aya_article:
                        print("üóëÔ∏è (‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡πÄ‡∏ö‡∏∑‡πà‡∏≠ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ)")
                        read_history.append(news_id)
                        new_items_found = True
                    else:
                        print("\n" + "üì∞"*20)
                        print(f"üìç {source['name']} | üïí {pub_date}")
                        print(aya_article)
                        if image_url: print(f"üñºÔ∏è Image: {image_url}")
                        print("-" * 50)
                        
                        # 3. ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ Discord ‡πÅ‡∏ö‡∏ö Embed (‡∏°‡∏µ‡∏£‡∏π‡∏õ)
                        if target_webhooks:
                            for i, webhook_url in enumerate(target_webhooks):
                                print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á (Embed) ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà {i+1}...")
                                # ‡∏™‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤, ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á, ‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                                send_discord_webhook(
                                    webhook_url, 
                                    aya_article, 
                                    source['name'], 
                                    news_url=entry.link, 
                                    image_url=image_url
                                )
                        else:
                            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DISCORD_WEBHOOK_URL")
                        
                        read_history.append(news_id)
                        new_items_found = True
                    
                    time.sleep(20) 

        except Exception as e:
            print(f"‚ö†Ô∏è Error accessing {source['name']}: {e}")

    if new_items_found:
        save_history(read_history)
        print("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    else:
        print("üí§ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà")

if __name__ == "__main__":
    run_once()
